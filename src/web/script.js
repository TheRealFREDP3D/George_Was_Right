document.addEventListener('DOMContentLoaded', () => {
    const llmProviderSelect = document.getElementById('llm-provider');
    const llmModelSelect = document.getElementById('llm-model');
    const runCrewButton = document.getElementById('run-crew');
    const searchToolSelect = document.getElementById('search-tool');
    const apiKeyInput = document.getElementById('api-key');

    const agentActionsLog = document.getElementById('agent-actions-log').querySelector('pre');
    const toolUsageLog = document.getElementById('tool-usage-log').querySelector('pre');
    const finalOutputDiv = document.getElementById('final-output');

    const logTabs = document.querySelectorAll('.log-tabs .tab-button');
    const logContents = document.querySelectorAll('.log-content');

    // --- Mock data for LLM models based on provider ---
    const llmModels = {
        openai: ['gpt-4', 'gpt-3.5-turbo', 'text-davinci-003'],
        anthropic: ['claude-2', 'claude-instant-1'],
        'google-gemini': ['gemini-pro', 'gemini-ultra'],
        // Add more providers and their models here
    };

    // --- Globals for interval management ---
    let mockAgentActionInterval = null;
    let mockToolUsageInterval = null;

    // --- Populate LLM models based on selected provider ---
    function populateLLMModels() {
        const selectedProvider = llmProviderSelect.value;
        llmModelSelect.innerHTML = ''; // Clear existing options

        if (llmModels[selectedProvider]) {
            llmModels[selectedProvider].forEach(model => {
                const option = document.createElement('option');
                option.value = model;
                option.textContent = model;
                llmModelSelect.appendChild(option);
            });
        } else {
            const option = document.createElement('option');
            option.textContent = 'No models available for this provider';
            llmModelSelect.appendChild(option);
        }
    }

    // --- Event Listeners ---
    if (llmProviderSelect) {
        llmProviderSelect.addEventListener('change', populateLLMModels);
    }

    if (runCrewButton) {
        runCrewButton.addEventListener('click', () => {
            // Prevent duplicate intervals by clearing any existing ones
            if (mockAgentActionInterval) clearInterval(mockAgentActionInterval);
            if (mockToolUsageInterval) clearInterval(mockToolUsageInterval);

            // Disable the button during execution
            runCrewButton.disabled = true;

            const settings = {
                searchTool: searchToolSelect.value,
                llmProvider: llmProviderSelect.value,
                llmModel: llmModelSelect.value,
                apiKey: apiKeyInput.value ? '******' : 'Not Provided' // Mask API key for display
            };
            console.log('Running Crew with settings:', settings);
            // Placeholder for actual run logic
            agentActionsLog.textContent = `Run initiated with ${settings.llmProvider} - ${settings.llmModel} and ${settings.searchTool} search.\n`;
            toolUsageLog.textContent = 'Waiting for tool usage...\n';
            finalOutputDiv.innerHTML = '<p>Crew execution started. Waiting for results...</p>';

            // TODO: Implement actual API call to backend to start the CrewAI process
            // Example:
            // fetch('/api/run-crew', {
            //     method: 'POST',
            //     headers: { 'Content-Type': 'application/json' },
            //     body: JSON.stringify(settings)
            // })
            // .then(response => response.json())
            // .then(data => {
            //     // Update logs and output based on data from backend
            //     // This would likely involve WebSockets for live updates
            // });

            // Mock live log updates (replace with actual WebSocket or SSE logic)
            let actionCounter = 1;
            mockAgentActionInterval = setInterval(() => {
                agentActionsLog.textContent += `Agent Action ${actionCounter++}: Thinking...\n`;
                agentActionsLog.scrollTop = agentActionsLog.scrollHeight; // Auto-scroll
            }, 2000);

            let toolCounter = 1;
            mockToolUsageInterval = setInterval(() => {
                toolUsageLog.textContent += `Tool Used ${toolCounter++}: SearchTool with query "example"\n`;
                toolUsageLog.scrollTop = toolUsageLog.scrollHeight; // Auto-scroll
            }, 3000);

            // Mock final output (replace with actual result)
            setTimeout(() => {
                clearInterval(mockAgentActionInterval);
                clearInterval(mockToolUsageInterval);
                mockAgentActionInterval = null;
                mockToolUsageInterval = null;
                agentActionsLog.textContent += 'Crew finished.\n';
                renderMarkdown("## Final Report\n\nThis is a *mockup* of the **final report** generated by CrewAI.\n\n- Item 1\n- Item 2\n\n```python\nprint('Hello CrewAI!')\n```");
                // Re-enable the button after execution
                runCrewButton.disabled = false;
            }, 10000); // Simulate a 10-second run
        });
    }

    // --- Tab switching for logs ---
    logTabs.forEach(tab => {
        tab.addEventListener('click', () => {
            // Deactivate all tabs and content
            logTabs.forEach(t => t.classList.remove('active'));
            logContents.forEach(c => c.classList.remove('active'));

            // Activate clicked tab and corresponding content
            tab.classList.add('active');
            const logType = tab.getAttribute('data-log');
            document.getElementById(`${logType}-log`).classList.add('active');
        });
    });

    // --- Markdown Rendering (using Marked.js for safe parsing) ---
    function renderMarkdown(markdownText) {
        // Use Marked.js for robust and safe Markdown parsing
        // Optionally, enable sanitization if needed (marked 4.x+ has sanitize option)
        // Example: marked.parse(markdownText, { sanitizer: ... })
        finalOutputDiv.innerHTML = marked.parse(markdownText);
    }

    // --- Initial Setup ---
    populateLLMModels(); // Populate LLM models on page load
    if (agentActionsLog) agentActionsLog.textContent = 'Waiting for agent actions...\n';
    if (toolUsageLog) toolUsageLog.textContent = 'Waiting for tool usage...\n';
    if (finalOutputDiv) finalOutputDiv.innerHTML = '<p>Final output will be rendered here.</p>';

});
